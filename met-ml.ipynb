{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "This notebook loads the ETL data and trains the LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples': 464187, 'lookback': 90, 'features': 6}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = xr.open_dataarray('./etl_data/x_train.nc')\n",
    "x_val = xr.open_dataarray('./etl_data/x_val.nc')\n",
    "y_train = xr.open_dataarray('./etl_data/y_train.nc')\n",
    "y_val = xr.open_dataarray('./etl_data/y_val.nc')\n",
    "dims = dict(zip(x_train.dims, x_train.shape))\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                2160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 2,181\n",
      "Trainable params: 2,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    '''Helper class to record the loss history'''\n",
    "    \n",
    "    def __init__(self, frequency=100):\n",
    "        self.frequency = frequency\n",
    "        self.batch_counter = 0\n",
    "        self.losses = []\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if batch % self.frequency == 0:\n",
    "            self.batch_counter += self.frequency\n",
    "            self.losses.append([logs.get('loss')])\n",
    "        \n",
    "fresh_model = True\n",
    "            \n",
    "if fresh_model:\n",
    "    input_shape = (dims['lookback'], dims['features'])\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(20, input_shape=input_shape, use_bias=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='3', optimizer='adam')\n",
    "else:\n",
    "    from keras.models import load_model\n",
    "    model = load_model('model.h5')\n",
    "    \n",
    "model.summary()\n",
    "    \n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 464187 samples, validate on 55000 samples\n",
      "Epoch 1/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 2/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 3/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 4/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 5/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 6/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 7/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 8/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 9/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 10/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 11/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 12/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 13/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 14/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 15/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 16/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 17/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 18/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 19/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 20/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 21/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 22/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 23/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 24/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 25/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 26/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 27/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 28/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 29/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 30/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 31/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 32/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 33/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 34/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 35/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 36/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 37/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 38/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 39/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 40/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 41/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 42/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 43/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 44/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 45/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 46/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 47/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 48/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 49/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 50/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 51/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 52/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 53/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 54/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 55/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 56/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 57/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 58/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 59/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 60/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 61/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 62/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 63/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 64/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 65/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 66/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 67/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 68/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 69/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 70/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 71/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 72/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 73/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 74/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 75/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 76/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 77/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 78/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 79/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 80/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 81/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 82/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 83/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 84/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 88/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 89/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 90/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 91/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 92/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 93/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 294/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 295/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 296/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 297/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 298/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 299/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 300/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 301/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 302/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 303/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 304/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 305/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 306/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 307/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 308/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 309/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 310/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 311/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 312/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 313/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 314/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 315/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 316/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 317/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 318/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 319/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 320/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 321/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 322/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 323/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 324/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 325/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 326/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 358/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 359/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 360/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 361/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 362/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 363/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 364/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 365/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 366/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 367/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 368/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 369/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 370/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 371/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 372/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 373/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 374/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 375/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 376/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 377/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 378/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 379/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 380/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 381/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 382/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 383/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 384/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 385/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 386/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 387/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 388/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 389/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 390/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 391/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 392/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 393/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 394/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 395/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 396/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 397/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 398/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 399/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 400/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 401/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 402/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 403/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 404/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 405/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 406/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 407/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 408/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 409/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 410/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 411/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 412/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 413/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 414/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 415/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 416/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 417/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 418/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 419/1000\n",
      "464187/464187 [==============================] - 2s 5us/sample - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 420/1000\n",
      " 40150/464187 [=>............................] - ETA: 2s - loss: 0.0070"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(x_train.values, y_train.values,\n",
    "              validation_data=(x_val.values, y_val.values),\n",
    "              batch_size=3650, epochs=3000,\n",
    "              shuffle=True, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = np.array(history.losses).squeeze()\n",
    "ds_hist = xr.Dataset({'loss': ('batch', loss)}).rolling(batch=100).mean()#.isel(batch=slice(-2000, -1))\n",
    "ds_hist.loss.plot()\n",
    "plt.xscale('symlog')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:projects-met-ml]",
   "language": "python",
   "name": "conda-env-projects-met-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
